{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport matplotlib.pyplot as plt \nimport sys\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom imblearn.pipeline import Pipeline\nimport time\nfrom sklearn.metrics import classification_report\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nimport warnings \nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.svm import SVC\nfrom sklearn.dummy import DummyClassifier\n#from sklearn.pipeline import Pipeline\n#from sklearn.feature_selection import VarianceThreshold\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.preprocessing import MinMaxScaler\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-03T18:33:52.903653Z","iopub.execute_input":"2021-12-03T18:33:52.904207Z","iopub.status.idle":"2021-12-03T18:33:54.109955Z","shell.execute_reply.started":"2021-12-03T18:33:52.904171Z","shell.execute_reply":"2021-12-03T18:33:54.109185Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# check in the file\nmonopati = \"/kaggle/input/sloan-digital-sky-survey-dr16/\"\nonomaSkyserver = \"Skyserver_12_30_2019 4_49_58 PM.csv\"\n\n#create the dataframe of the csv file \ndata = pd.read_csv(monopati+onomaSkyserver)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T18:33:59.645944Z","iopub.execute_input":"2021-12-03T18:33:59.646439Z","iopub.status.idle":"2021-12-03T18:34:00.108814Z","shell.execute_reply.started":"2021-12-03T18:33:59.646402Z","shell.execute_reply":"2021-12-03T18:34:00.108018Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# checking in the dataframe \nprint(\"The infos for the sky dataframe \\n\")\nprint(data.info())\nprint(\"\\nAre there any zeros or missing values? \\n\")\nprint(data.isnull().sum())\nprint(\"\\nDifferent metrics from dataset \\n\")\nprint(data.describe())\nprint(\"\\nReverse different metrics from dataset \\n\")\nprint(data.describe().T)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T10:42:02.777257Z","iopub.execute_input":"2021-12-03T10:42:02.777512Z","iopub.status.idle":"2021-12-03T10:42:02.990151Z","shell.execute_reply.started":"2021-12-03T10:42:02.777482Z","shell.execute_reply":"2021-12-03T10:42:02.989340Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# checking if dataset is imbalanced\nprint(data['class'].value_counts())\n\n#with the difficult way \n# df --> numpy \nsky = pd.DataFrame(data).to_numpy()\n\n#print(sky[:,13]) #for some reason the class -> 13\nklaseis, number_in_klaseis = np.unique(sky[:,13],return_counts=True)\n\nprint(\"There are \"+str(number_in_klaseis[0])+\" samples of \"+str(klaseis[0]))\nprint(\"There are \"+str(number_in_klaseis[1])+\" samples of \"+str(klaseis[1]))\nprint(\"There are \"+str(number_in_klaseis[2])+\" samples of \"+str(klaseis[2]))\nprint(\"The biggest different between classes is : \"+str(max(number_in_klaseis)/min(number_in_klaseis)))\nif max(number_in_klaseis)/min(number_in_klaseis) > 1.5 :\n    print(\"WARNING! The dataset is imbalanced!\")","metadata":{"execution":{"iopub.status.busy":"2021-12-03T18:34:15.916347Z","iopub.execute_input":"2021-12-03T18:34:15.916770Z","iopub.status.idle":"2021-12-03T18:34:16.143938Z","shell.execute_reply.started":"2021-12-03T18:34:15.916737Z","shell.execute_reply":"2021-12-03T18:34:16.143132Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def sns_distribution(plotter,titlos):\n    sns.set_style('darkgrid')\n    plt.figure(figsize = (8,6))\n    plt.title(titlos)\n    sns.countplot(plotter, palette = 'magma')\n    plt.show()\n    return None\n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T18:34:19.942368Z","iopub.execute_input":"2021-12-03T18:34:19.942663Z","iopub.status.idle":"2021-12-03T18:34:19.947599Z","shell.execute_reply.started":"2021-12-03T18:34:19.942632Z","shell.execute_reply":"2021-12-03T18:34:19.946837Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#let's check our classes \nsns_distribution(data['class'],\"Classes of dataset\")","metadata":{"execution":{"iopub.status.busy":"2021-12-03T11:15:31.235986Z","iopub.execute_input":"2021-12-03T11:15:31.236441Z","iopub.status.idle":"2021-12-03T11:15:31.534201Z","shell.execute_reply.started":"2021-12-03T11:15:31.236404Z","shell.execute_reply":"2021-12-03T11:15:31.533480Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#################################\n\"\"\" Make the dataset balanced \"\"\"\n#################################\n\n#take X, y of dataset \nX = data.drop('class',axis=1).values\ny = data['class'].values\nprint(X.shape)\nprint(y.shape)\n\n#Oversampling \n# define oversampling strategy\noversampler = RandomOverSampler(sampling_strategy=dict({'STAR': 38096, 'GALAXY': 51323, 'QSO': 16000}))\n# fit and apply the transform\nX_over, y_over = oversampler.fit_resample(X, y)\nprint(X_over.shape)\nprint(y_over.shape)\n\n#Downsampling \n# define undersampling strategy\ndownsampler = RandomUnderSampler(sampling_strategy=dict({'STAR': 17500, 'GALAXY': 22000, 'QSO': 16000}))\n# fit and apply the transform\nX_down, y_down = downsampler.fit_resample(X_over, y_over)\nprint(X_down.shape)\nprint(y_down.shape)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T18:34:36.990163Z","iopub.execute_input":"2021-12-03T18:34:36.990646Z","iopub.status.idle":"2021-12-03T18:34:38.120338Z","shell.execute_reply.started":"2021-12-03T18:34:36.990606Z","shell.execute_reply":"2021-12-03T18:34:38.119570Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#check if dataset is balanced\nklaseis_bal, number_in_klaseis_bal = np.unique(y_down,return_counts=True)\n\nprint(\"There are \"+str(number_in_klaseis_bal[0])+\" samples of \"+str(klaseis_bal[0]))\nprint(\"There are \"+str(number_in_klaseis_bal[1])+\" samples of \"+str(klaseis_bal[1]))\nprint(\"There are \"+str(number_in_klaseis_bal[2])+\" samples of \"+str(klaseis_bal[2]))\nprint(\"The biggest different between classes is : \"+str(max(number_in_klaseis_bal)/min(number_in_klaseis_bal)))\n\nif max(number_in_klaseis_bal)/min(number_in_klaseis_bal) > 1.5 :\n    print(\"WARNING! The dataset is imbalanced!\")\nelse : \n    print(\"Teehee! The dataset is balanced\")\n    \nsns_distribution(y_down,\"Classes of Balanced dataset\")","metadata":{"execution":{"iopub.status.busy":"2021-12-03T18:34:41.728015Z","iopub.execute_input":"2021-12-03T18:34:41.728779Z","iopub.status.idle":"2021-12-03T18:34:42.053139Z","shell.execute_reply.started":"2021-12-03T18:34:41.728738Z","shell.execute_reply":"2021-12-03T18:34:42.052391Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"###########################\n\"\"\" split file into X y \"\"\"\n###########################\n\nX_train, X_test, y_train, y_test = train_test_split(X_down, y_down, test_size=0.30, shuffle=True)\n\n#check if splitting is okey for y train\ny_tr_class, plithos_y_tr_class = np.unique(y_train,return_counts=True)\nprint(\"There are \"+str(plithos_y_tr_class[0])+\" samples of \"+str(y_tr_class[0]))\nprint(\"There are \"+str(plithos_y_tr_class[1])+\" samples of \"+str(y_tr_class[1]))\nprint(\"There are \"+str(plithos_y_tr_class[2])+\" samples of \"+str(y_tr_class[2]))\nprint(\"The biggest different between classes is : \"+str(max(plithos_y_tr_class)/min(plithos_y_tr_class)))\nsns_distribution(y_train,\"Classes of y train\")\n\n#check if splitting is okey for y test\ny_te_class, plithos_y_te_class = np.unique(y_test,return_counts=True)\nprint(\"There are \"+str(plithos_y_te_class[0])+\" samples of \"+str(y_te_class[0]))\nprint(\"There are \"+str(plithos_y_te_class[1])+\" samples of \"+str(y_te_class[1]))\nprint(\"There are \"+str(plithos_y_te_class[2])+\" samples of \"+str(y_te_class[2]))\nprint(\"The biggest different between classes is : \"+str(max(plithos_y_te_class)/min(plithos_y_te_class)))\nsns_distribution(y_test,\"Classes of y test\")\n\n\n## take a slice of the dataset \n## to run quickly the evaluation\n\n# define undersampling strategy cut 0\ndown_0 = RandomUnderSampler(sampling_strategy=dict({'STAR': 1600, 'GALAXY': 2100, 'QSO': 1300}))\n# fit and apply the transform\nX_sample, y_sample = down_0.fit_resample(X_down, y_down)\n#print(X_sample.shape)\n#print(y_sample.shape)\n\nXs_train, Xs_test, ys_train, ys_test = train_test_split(X_sample, y_sample, test_size=0.30, shuffle=True)\n\n#check if spliting is okey for the sample y train\nys_tr_class, plithos_ys_tr_class = np.unique(ys_train,return_counts=True)\nprint(\"There are \"+str(plithos_ys_tr_class[0])+\" samples of \"+str(ys_tr_class[0]))\nprint(\"There are \"+str(plithos_ys_tr_class[1])+\" samples of \"+str(ys_tr_class[1]))\nprint(\"There are \"+str(plithos_ys_tr_class[2])+\" samples of \"+str(ys_tr_class[2]))\nprint(\"The biggest different between classes is : \"+str(max(plithos_ys_tr_class)/min(plithos_ys_tr_class)))\nsns_distribution(ys_train,\"Classes of the sample of y train\")\n\n#check if spliting is okey for the sample y test\nys_te_class, plithos_ys_te_class = np.unique(ys_test,return_counts=True)\nprint(\"There are \"+str(plithos_ys_te_class[0])+\" samples of \"+str(ys_te_class[0]))\nprint(\"There are \"+str(plithos_ys_te_class[1])+\" samples of \"+str(ys_te_class[1]))\nprint(\"There are \"+str(plithos_ys_te_class[2])+\" samples of \"+str(ys_te_class[2]))\nprint(\"The biggest different between classes is : \"+str(max(plithos_ys_te_class)/min(plithos_ys_te_class)))\nsns_distribution(ys_test,\"Classes of the sample of y test\")\n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T18:34:45.651452Z","iopub.execute_input":"2021-12-03T18:34:45.651810Z","iopub.status.idle":"2021-12-03T18:34:46.898041Z","shell.execute_reply.started":"2021-12-03T18:34:45.651772Z","shell.execute_reply":"2021-12-03T18:34:46.897362Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def SimpleAccuracy(taxinomitis, Xi_tr, yi_tr, Xi_te, yi_te, epilogeas, anafora):\n    #declare classifier\n    clf = taxinomitis\n    \n    #check train time\n    start_time1 = time.time()\n    _ = clf.fit(Xi_tr, yi_tr)\n    train_time = time.time() - start_time1\n    \n    #check test time\n    start_time2 = time.time()\n    yi_predi = clf.predict(Xi_te)\n    test_time = time.time() - start_time2\n    \n    #classification report\n    if anafora :\n        print(classification_report(yi_te, yi_predi))\n    \n    if epilogeas == 'aplo' :\n        score = clf.score(Xi_te, yi_te)\n    if epilogeas == 'accur' :\n        score = metrics.accuracy_score(yi_te, yi_predi)\n    if epilogeas == 'Fena' :\n        score = metrics.f1_score(yi_te, yi_predi,average='macro')\n    if epilogeas == 'Recall' :\n        score = metrics.recall_score(yi_te, yi_predi,average='macro')\n    if epilogeas == 'Precision' :\n        score = metrics.precision_score(yi_te, yi_predi,average='macro')\n  \n    return clf, score, train_time, test_time","metadata":{"execution":{"iopub.status.busy":"2021-12-03T18:34:54.369860Z","iopub.execute_input":"2021-12-03T18:34:54.370632Z","iopub.status.idle":"2021-12-03T18:34:54.378826Z","shell.execute_reply.started":"2021-12-03T18:34:54.370594Z","shell.execute_reply":"2021-12-03T18:34:54.377838Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"###############################################\n\"\"\"out of the box for the imbalanced dataset\"\"\"\n###############################################\n\nXim_train, Xim_test, yim_train, yim_test = train_test_split(X, y, test_size=0.30, shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T18:34:59.594116Z","iopub.execute_input":"2021-12-03T18:34:59.594902Z","iopub.status.idle":"2021-12-03T18:34:59.620697Z","shell.execute_reply.started":"2021-12-03T18:34:59.594851Z","shell.execute_reply":"2021-12-03T18:34:59.619965Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"###########\n### MLP ###\n###########\n\nmlp_im, _, mlp_im_train_time, mlp_im_test_time = SimpleAccuracy(MLPClassifier(), Xim_train, yim_train, Xim_test, yim_test, 'aplo', True)\n_, mlp_im_simple_score, _, _ = SimpleAccuracy(MLPClassifier(), Xim_train, yim_train, Xim_test, yim_test, 'aplo', False)\n_, mlp_im_accur_score, _, _ = SimpleAccuracy(MLPClassifier(), Xim_train, yim_train, Xim_test, yim_test, 'accur', False)\n_, mlp_im_f1_score, _, _ = SimpleAccuracy(MLPClassifier(), Xim_train, yim_train, Xim_test, yim_test, 'Fena', False)\n_, mlp_im_recall_score, _, _ = SimpleAccuracy(MLPClassifier(), Xim_train, yim_train, Xim_test, yim_test, 'Recall', False)\n_, mlp_im_precision_score, _, _ = SimpleAccuracy(MLPClassifier(), Xim_train, yim_train, Xim_test, yim_test, 'Precision', False)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T12:06:11.342236Z","iopub.execute_input":"2021-12-03T12:06:11.343000Z","iopub.status.idle":"2021-12-03T12:09:09.337439Z","shell.execute_reply.started":"2021-12-03T12:06:11.342948Z","shell.execute_reply":"2021-12-03T12:09:09.336695Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"#print the results for MLP for the imbalanced dataset\nprint(\"The simple score of MLP for the IMbalanced dataset is : \"+str(mlp_im_simple_score))\nprint(\"The accuracy score of MLP for the IMbalanced dataset is : \"+str(mlp_im_accur_score))\nprint(\"The f1 score of MLP for the IMbalanced dataset is : \"+str(mlp_im_f1_score))\nprint(\"The recall score of MLP for the IMbalanced dataset is : \"+str(mlp_im_recall_score))\nprint(\"The precision score of MLP for the IMbalanced dataset is : \"+str(mlp_im_precision_score))\nprint(\"The trainig time for the MLP for the IMbalanced dataset is : \"+str(mlp_im_train_time))\nprint(\"The test time for the MLP for the IMbalanced dataset is : \"+str(mlp_im_test_time))\n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T12:14:01.302883Z","iopub.execute_input":"2021-12-03T12:14:01.303353Z","iopub.status.idle":"2021-12-03T12:14:01.311722Z","shell.execute_reply.started":"2021-12-03T12:14:01.303317Z","shell.execute_reply":"2021-12-03T12:14:01.310920Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"###########\n### SVC ###\n###########\n\nsvc_im, _, svc_im_train_time, svc_im_test_time = SimpleAccuracy(SVC(), Xim_train, yim_train, Xim_test, yim_test, 'aplo', True)\n_, svc_simple_score, _, _ = SimpleAccuracy(SVC(), Xim_train, yim_train, Xim_test, yim_test, 'aplo', False)\n_, svc_accur_score, _, _ = SimpleAccuracy(SVC(), Xim_train, yim_train, Xim_test, yim_test, 'accur', False)\n_, svc_f1_score, _, _ = SimpleAccuracy(SVC(), Xim_train, yim_train, Xim_test, yim_test, 'Fena', False)\n_, svc_recall_score, _, _ = SimpleAccuracy(SVC(), Xim_train, yim_train, Xim_test, yim_test, 'Recall', False)\n_, svc_precision_score, _, _ = SimpleAccuracy(SVC(), Xim_train, yim_train, Xim_test, yim_test, 'Precision', False)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T12:17:07.700880Z","iopub.execute_input":"2021-12-03T12:17:07.701383Z","iopub.status.idle":"2021-12-03T12:55:15.873201Z","shell.execute_reply.started":"2021-12-03T12:17:07.701346Z","shell.execute_reply":"2021-12-03T12:55:15.872328Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"#print the results for MLP for the imbalanced dataset\nprint(\"The simple score of SVC for the IMbalanced dataset is : \"+str(svc_simple_score))\nprint(\"The accuracy score of SVC for the IMbalanced dataset is : \"+str(svc_accur_score))\nprint(\"The f1 score of SVC for the IMbalanced dataset is : \"+str(svc_f1_score))\nprint(\"The recall score of SVC for the IMbalanced dataset is : \"+str(svc_recall_score))\nprint(\"The precision score of SVC for the IMbalanced dataset is : \"+str(svc_precision_score))\nprint(\"The trainig time for the SVC for the IMbalanced dataset is : \"+str(svc_im_train_time))\nprint(\"The test time for the SVC for the IMbalanced dataset is : \"+str(svc_im_test_time))\n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T12:58:38.562043Z","iopub.execute_input":"2021-12-03T12:58:38.562319Z","iopub.status.idle":"2021-12-03T12:58:38.570075Z","shell.execute_reply.started":"2021-12-03T12:58:38.562287Z","shell.execute_reply":"2021-12-03T12:58:38.569241Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"#############################################\n\"\"\"out of the box for the Balanced dataset\"\"\"\n#############################################\n\n#for the MLP - balanced dataset\nmlp_bal, _, mlp_bal_train_time, mlp_bal_test_time = SimpleAccuracy(MLPClassifier(), X_train, y_train, X_test, y_test, 'aplo', True)\n_, mlp_bal_simple_score, _, _ = SimpleAccuracy(MLPClassifier(), X_train, y_train, X_test, y_test, 'aplo', False)\n_, mlp_bal_accur_score, _, _ = SimpleAccuracy(MLPClassifier(), X_train, y_train, X_test, y_test, 'accur', False)\n_, mlp_bal_f1_score, _, _ = SimpleAccuracy(MLPClassifier(), X_train, y_train, X_test, y_test, 'Fena', False)\n_, mlp_bal_recall_score, _, _ = SimpleAccuracy(MLPClassifier(), X_train, y_train, X_test, y_test, 'Recall', False)\n_, mlp_bal_precision_score, _, _ = SimpleAccuracy(MLPClassifier(), X_train, y_train, X_test, y_test, 'Precision', False)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:11:34.931157Z","iopub.execute_input":"2021-12-03T13:11:34.931417Z","iopub.status.idle":"2021-12-03T13:12:55.740998Z","shell.execute_reply.started":"2021-12-03T13:11:34.931388Z","shell.execute_reply":"2021-12-03T13:12:55.740283Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"#print the results for MLP for the Balanced dataset\nprint(\"The simple score of MLP for the Balanced dataset is : \"+str(mlp_bal_simple_score))\nprint(\"The accuracy score of MLP for the Balanced dataset is : \"+str(mlp_bal_accur_score))\nprint(\"The f1 score of MLP for the Balanced dataset is : \"+str(mlp_bal_f1_score))\nprint(\"The recall score of MLP for the Balanced dataset is : \"+str(mlp_bal_recall_score))\nprint(\"The precision score of MLP for the Balanced dataset is : \"+str(mlp_bal_precision_score))\nprint(\"The trainig time for the MLP for the Balanced dataset is : \"+str(mlp_bal_train_time))\nprint(\"The test time for the MLP for the Balanced dataset is : \"+str(mlp_bal_test_time))\n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:13:25.708558Z","iopub.execute_input":"2021-12-03T13:13:25.709106Z","iopub.status.idle":"2021-12-03T13:13:25.717210Z","shell.execute_reply.started":"2021-12-03T13:13:25.709069Z","shell.execute_reply":"2021-12-03T13:13:25.716392Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"#for the SVC - balanced dataset\nsvc_bal, _, svc_bal_train_time, svc_bal_test_time = SimpleAccuracy(SVC(), X_train, y_train, X_test, y_test, 'aplo', True)\n_, svc_bal_simple_score, _, _ = SimpleAccuracy(SVC(), X_train, y_train, X_test, y_test, 'aplo', False)\n_, svc_bal_accur_score, _, _ = SimpleAccuracy(SVC(), X_train, y_train, X_test, y_test, 'accur', False)\n_, svc_bal_f1_score, _, _ = SimpleAccuracy(SVC(), X_train, y_train, X_test, y_test, 'Fena', False)\n_, svc_bal_recall_score, _, _ = SimpleAccuracy(SVC(), X_train, y_train, X_test, y_test, 'Recall', False)\n_, svc_bal_precision_score, _, _ = SimpleAccuracy(SVC(), X_train, y_train, X_test, y_test, 'Precision', False)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:16:16.313459Z","iopub.execute_input":"2021-12-03T13:16:16.314193Z","iopub.status.idle":"2021-12-03T13:30:18.119853Z","shell.execute_reply.started":"2021-12-03T13:16:16.314155Z","shell.execute_reply":"2021-12-03T13:30:18.119157Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"#print the results for MLP for the Balanced dataset\nprint(\"The simple score of SVC for the Balanced dataset is : \"+str(svc_bal_simple_score))\nprint(\"The accuracy score of SVC for the Balanced dataset is : \"+str(svc_bal_accur_score))\nprint(\"The f1 score of SVC for the Balanced dataset is : \"+str(svc_bal_f1_score))\nprint(\"The recall score of SVC for the Balanced dataset is : \"+str(svc_bal_recall_score))\nprint(\"The precision score of SVC for the Balanced dataset is : \"+str(svc_bal_precision_score))\nprint(\"The trainig time for the SVC for the Balanced dataset is : \"+str(svc_bal_train_time))\nprint(\"The test time for the SVC for the Balanced dataset is : \"+str(svc_bal_test_time))\n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:30:31.880420Z","iopub.execute_input":"2021-12-03T13:30:31.880682Z","iopub.status.idle":"2021-12-03T13:30:31.890294Z","shell.execute_reply.started":"2021-12-03T13:30:31.880637Z","shell.execute_reply":"2021-12-03T13:30:31.889474Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"#for the Dummy - balanced dataset\ndc_bal, _, dc_bal_train_time, dc_bal_test_time = SimpleAccuracy(DummyClassifier(), X_train, y_train, X_test, y_test, 'aplo', True)\n_, dc_bal_simple_score, _, _ = SimpleAccuracy(DummyClassifier(), X_train, y_train, X_test, y_test, 'aplo', False)\n_, dc_bal_accur_score, _, _ = SimpleAccuracy(DummyClassifier(), X_train, y_train, X_test, y_test, 'accur', False)\n_, dc_bal_f1_score, _, _ = SimpleAccuracy(DummyClassifier(), X_train, y_train, X_test, y_test, 'Fena', False)\n_, dc_bal_recall_score, _, _ = SimpleAccuracy(DummyClassifier(), X_train, y_train, X_test, y_test, 'Recall', False)\n_, dc_bal_precision_score, _, _ = SimpleAccuracy(DummyClassifier(), X_train, y_train, X_test, y_test, 'Precision', False)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T14:11:42.551935Z","iopub.execute_input":"2021-12-03T14:11:42.552471Z","iopub.status.idle":"2021-12-03T14:11:44.255699Z","shell.execute_reply.started":"2021-12-03T14:11:42.552434Z","shell.execute_reply":"2021-12-03T14:11:44.254999Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"#print the results for Dummy for the Balanced dataset\nprint(\"The simple score of Dummy for the Balanced dataset is : \"+str(dc_bal_simple_score))\nprint(\"The accuracy score of Dummy for the Balanced dataset is : \"+str(dc_bal_accur_score))\nprint(\"The f1 score of Dummy for the Balanced dataset is : \"+str(dc_bal_f1_score))\nprint(\"The recall score of Dummy for the Balanced dataset is : \"+str(dc_bal_recall_score))\nprint(\"The precision score of Dummy for the Balanced dataset is : \"+str(dc_bal_precision_score))\nprint(\"The trainig time for the Dummy for the Balanced dataset is : \"+str(dc_bal_train_time))\nprint(\"The test time for the Dummy for the Balanced dataset is : \"+str(dc_bal_test_time))\n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T14:12:34.571107Z","iopub.execute_input":"2021-12-03T14:12:34.571538Z","iopub.status.idle":"2021-12-03T14:12:34.579059Z","shell.execute_reply.started":"2021-12-03T14:12:34.571501Z","shell.execute_reply":"2021-12-03T14:12:34.578329Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"################\n### PLOT BAR ###\n################\n\ndef plot_bares(pinakas, onomaTA, titlos):\n    polichromo3 = ['blue','orange','green']\n    plt.bar(onomaTA , pinakas,color=polichromo3)\n    plt.xlabel(\"Estimators used\")\n    plt.ylabel(\"Estimators scores \")\n    plt.title(titlos)\n    plt.show()\n    print('\\n')\n    return None\n\ndef plot_AccurANDf1(bara_1, bara_2, onomata, Leganda, titlos):\n    x_len = np.arange(len(onomata))\n    w_bar = 0.36\n    plt.bar(x_len-(w_bar/2), bara_1, width = w_bar)\n    plt.bar(x_len+(w_bar/2), bara_2, width = w_bar)\n    #plt.xlabel(\"Estimators used\")\n    plt.xticks(x_len, labels = onomata)\n    plt.ylabel(\"Scores of Classifiers \")\n    plt.legend(Leganda,loc='best')\n    plt.title(titlos)\n    plt.show()\n    return None\n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T18:50:33.811191Z","iopub.execute_input":"2021-12-03T18:50:33.811443Z","iopub.status.idle":"2021-12-03T18:50:33.821788Z","shell.execute_reply.started":"2021-12-03T18:50:33.811415Z","shell.execute_reply":"2021-12-03T18:50:33.820936Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# put all the results in lists\nclfs3_names = [\"Dummy\",\"MLP\",\"SVC\"]\ncls3_fitted = [dc_bal, mlp_bal, svc_bal]\nclfs3_simple_scores = [dc_bal_simple_score, mlp_bal_simple_score, svc_bal_simple_score]\nclfs3_accur_scores = [dc_bal_accur_score, mlp_bal_accur_score, svc_bal_accur_score]\nclfs3_f1_scores = [dc_bal_f1_score, mlp_bal_f1_score, svc_bal_f1_score]\nclfs3_recall_scores = [dc_bal_recall_score, mlp_bal_recall_score, svc_bal_recall_score]\nclfs3_precision_scores = [dc_bal_precision_score, mlp_bal_precision_score, svc_bal_precision_score]\nclfs3_train_time = [dc_bal_train_time, mlp_bal_train_time, svc_bal_train_time]\nclfs3_test_time = [dc_bal_test_time, mlp_bal_test_time, svc_bal_test_time]","metadata":{"execution":{"iopub.status.busy":"2021-12-03T15:12:04.943431Z","iopub.execute_input":"2021-12-03T15:12:04.944002Z","iopub.status.idle":"2021-12-03T15:12:04.950050Z","shell.execute_reply.started":"2021-12-03T15:12:04.943962Z","shell.execute_reply":"2021-12-03T15:12:04.948988Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"plot_bares(clfs3_simple_scores, clfs3_names, \"Accuracy per Classifier with simple scoring \")\nplot_bares(clfs3_accur_scores, clfs3_names, \"Accuracy per Classifier with accuracy scoring \")\nplot_bares(clfs3_f1_scores, clfs3_names, \"Accuracy per Classifier with f1 macro scoring \")\nplot_bares(clfs3_recall_scores, clfs3_names, \"Accuracy per Classifier with recall scoring \")\nplot_bares(clfs3_precision_scores, clfs3_names, \"Accuracy per Classifier with precision scoring \")\nplot_bares(clfs3_train_time, clfs3_names, \"Train times Per Classifier\")\nplot_bares(clfs3_test_time, clfs3_names, \"Test times Per Classifier \")","metadata":{"execution":{"iopub.status.busy":"2021-12-03T14:48:05.814758Z","iopub.execute_input":"2021-12-03T14:48:05.815220Z","iopub.status.idle":"2021-12-03T14:48:07.401509Z","shell.execute_reply.started":"2021-12-03T14:48:05.815181Z","shell.execute_reply":"2021-12-03T14:48:07.400818Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"plot_AccurANDf1(clfs3_accur_scores, clfs3_f1_scores, clfs3_names, ['accuracy','f1_macro'], \"Accuracy per Classifier\")\nplot_AccurANDf1(clfs3_recall_scores, clfs3_precision_scores, clfs3_names, ['Recall','Precision'], \"Recall-Precision per Classifier\")\nplot_AccurANDf1(clfs3_train_time, clfs3_test_time, clfs3_names,['train time','test time'],\"Train - Test times\")","metadata":{"execution":{"iopub.status.busy":"2021-12-03T14:45:01.076243Z","iopub.execute_input":"2021-12-03T14:45:01.076507Z","iopub.status.idle":"2021-12-03T14:45:01.688228Z","shell.execute_reply.started":"2021-12-03T14:45:01.076479Z","shell.execute_reply":"2021-12-03T14:45:01.687500Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n    markdown tables \n    def from the stack overflow \n    https://stackoverflow.com/questions/13394140/generate-markdown-tables\n\n\"\"\"\n\n# Translation dictionaries for table alignment\nleft_rule = {'<': ':', '^': ':', '>': '-'}\nright_rule = {'<': '-', '^': ':', '>': ':'}\n\ndef evalute_field(record, field_spec):\n    \"\"\"\n    Evalute a field of a record using the type of the field_spec as a guide.\n    \"\"\"\n    if type(field_spec) is int:\n        return str(record[field_spec])\n    elif type(field_spec) is str:\n        return str(getattr(record, field_spec))\n    else:\n        return str(field_spec(record))\n\ndef table(file, records, fields, headings, alignment = None):\n    num_columns = len(fields)\n    assert len(headings) == num_columns\n\n    # Compute the table cell data\n    columns = [[] for i in range(num_columns)]\n    for record in records:\n        for i, field in enumerate(fields):\n            columns[i].append(evalute_field(record, field))\n\n    # Fill out any missing alignment characters.\n    extended_align = alignment if alignment != None else []\n    if len(extended_align) > num_columns:\n        extended_align = extended_align[0:num_columns]\n    elif len(extended_align) < num_columns:\n        extended_align += [('^', '<')\n                           for i in range[num_columns-len(extended_align)]]\n\n    heading_align, cell_align = [x for x in zip(*extended_align)]\n\n    field_widths = [len(max(column, key=len)) if len(column) > 0 else 0\n                    for column in columns]\n    heading_widths = [max(len(head), 2) for head in headings]\n    column_widths = [max(x) for x in zip(field_widths, heading_widths)]\n\n    _ = ' | '.join(['{:' + a + str(w) + '}'\n                    for a, w in zip(heading_align, column_widths)])\n    heading_template = '| ' + _ + ' |'\n    _ = ' | '.join(['{:' + a + str(w) + '}'\n                    for a, w in zip(cell_align, column_widths)])\n    row_template = '| ' + _ + ' |'\n\n    _ = ' | '.join([left_rule[a] + '-'*(w-2) + right_rule[a]\n                    for a, w in zip(cell_align, column_widths)])\n    ruling = '| ' + _ + ' |'\n\n    file.write(heading_template.format(*headings).rstrip() + '\\n')\n    file.write(ruling.rstrip() + '\\n')\n    for row in zip(*columns):\n        file.write(row_template.format(*row).rstrip() + '\\n')\n\n    return None \n\ndef markdownCreator(titlos,epikefalides,dedomena):\n  \n  sys.stdout.write(titlos+'\\n\\n')\n\n  fields = np.ndarray.tolist(np.arange(len(epikefalides)))\n\n  align = [('^', '<'), ('^', '^'), ('^', '<'), ('^', '^'), ('^', '>'),('^','^')]\n\n  table(sys.stdout, dedomena, fields, epikefalides, align)\n\n  return None","metadata":{"execution":{"iopub.status.busy":"2021-12-03T18:35:24.469589Z","iopub.execute_input":"2021-12-03T18:35:24.469859Z","iopub.status.idle":"2021-12-03T18:35:24.486938Z","shell.execute_reply.started":"2021-12-03T18:35:24.469829Z","shell.execute_reply":"2021-12-03T18:35:24.486038Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"titlos_mark1 = 'The accuracies for the classifiers with default parameters and different metrics' \nepikefalides_mark1 = ['Classifiers', 'Dummy', 'MLP', 'SVC']\ndedomena_mark1 = [('Simple Score',str(clfs3_simple_scores[0]),str(clfs3_simple_scores[1]),str(clfs3_simple_scores[2])),\n                  ('Accuracy Score', str(clfs3_accur_scores[0]),str(clfs3_accur_scores[1]),str(clfs3_accur_scores[2])),\n                  ('f1 macro', str(clfs3_f1_scores[0]), str(clfs3_f1_scores[1]), str(clfs3_f1_scores[2])),\n                  ('Recall', str(clfs3_recall_scores[0]), str(clfs3_recall_scores[1]), str(clfs3_recall_scores[2])),\n                  ('Precision', str(clfs3_precision_scores[0]), str(clfs3_precision_scores[1]), str(clfs3_precision_scores[2])),\n                  ('Train time', str(clfs3_train_time[0]), str(clfs3_train_time[1]), str(clfs3_train_time[2])),\n                  ('Test time', str(clfs3_test_time[0]), str(clfs3_test_time[1]), str(clfs3_test_time[2]))]\n\nmarkdownCreator(titlos_mark1, epikefalides_mark1, dedomena_mark1)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T15:00:55.415997Z","iopub.execute_input":"2021-12-03T15:00:55.416802Z","iopub.status.idle":"2021-12-03T15:00:55.427694Z","shell.execute_reply.started":"2021-12-03T15:00:55.416751Z","shell.execute_reply":"2021-12-03T15:00:55.426774Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"###########################\n\"\"\" confusion matrixies \"\"\"\n###########################\n\nfor clasi in cls3_fitted:\n  #plt.figure(figsize = (9,9))\n  plot_confusion_matrix(clasi, X_test, y_test) \n  plt.title(\"The confusion matrix for the \"+str(clasi))\n  plt.show()\n  \n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T15:12:24.824194Z","iopub.execute_input":"2021-12-03T15:12:24.824471Z","iopub.status.idle":"2021-12-03T15:12:47.034509Z","shell.execute_reply.started":"2021-12-03T15:12:24.824440Z","shell.execute_reply":"2021-12-03T15:12:47.033820Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"################################\n\"\"\" 10 fold cross validation \"\"\"\n################################\n\ndef evaluate_10F(clf, Xi, yi, folds, eidos_accuracy):\n\n    start_time = time.time()\n    scores_fcv = cross_val_score(clf, Xi, yi,\n                                 cv=KFold(n_splits=folds, random_state=32, shuffle=True),\n                                 scoring=eidos_accuracy)\n\n    stop_time = time.time() - start_time \n    print(\"The scores on each of the \"+str(folds)+\" splits with \"+eidos_accuracy+\" for \"+str(clf),scores_fcv)\n    \n    mean_scores_fcv = np.mean(scores_fcv)\n    print(\"The mean score with \"+eidos_accuracy+\" for \"+str(clf)+\" is \"+str(mean_scores_fcv)+\"\\n\")\n    \n    return mean_scores_fcv,stop_time","metadata":{"execution":{"iopub.status.busy":"2021-12-03T18:35:44.776954Z","iopub.execute_input":"2021-12-03T18:35:44.777218Z","iopub.status.idle":"2021-12-03T18:35:44.783743Z","shell.execute_reply.started":"2021-12-03T18:35:44.777189Z","shell.execute_reply":"2021-12-03T18:35:44.782755Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"down_hyper = RandomUnderSampler(sampling_strategy=dict({'STAR': 1600, 'GALAXY': 2100, 'QSO': 1300}))\n# fit and apply the transform\nX_sample, y_sample = down_hyper.fit_resample(X_down, y_down)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T18:38:21.319863Z","iopub.execute_input":"2021-12-03T18:38:21.320139Z","iopub.status.idle":"2021-12-03T18:38:21.653412Z","shell.execute_reply.started":"2021-12-03T18:38:21.320110Z","shell.execute_reply":"2021-12-03T18:38:21.652594Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#define the lists to run 10 fcv\nclfs3 = [DummyClassifier(), MLPClassifier(), SVC()]\nclfs3_10F_accur_scores = []\nclfs3_10F_accur_times = []\nclfs3_10F_f1_scores = []\nclfs3_10F_f1_times = []\nclfs3_10F_recall_scores = []\nclfs3_10F_recall_times = []\nclfs3_10F_precision_scores = []\nclfs3_10F_precision_times = []\n\naccur_metrics = ['accuracy','f1_macro','recall_macro','precision_macro']\nfor clasi in clfs3:\n    for metriki in accur_metrics:\n        score_10f_help, time_10f_help = evaluate_10F(clasi, X_sample, y_sample, 10, metriki)\n        if metriki == 'accuracy':\n            clfs3_10F_accur_scores.append(score_10f_help)\n            clfs3_10F_accur_times.append(time_10f_help)\n        if metriki == 'f1_macro':\n            clfs3_10F_f1_scores.append(score_10f_help)\n            clfs3_10F_f1_times.append(time_10f_help)\n        if metriki == 'recall_macro':\n            clfs3_10F_recall_scores.append(score_10f_help)\n            clfs3_10F_recall_times.append(time_10f_help)\n        if metriki == 'precision_macro':\n            clfs3_10F_precision_scores.append(score_10f_help)\n            clfs3_10F_precision_times.append(time_10f_help)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T18:40:40.507884Z","iopub.execute_input":"2021-12-03T18:40:40.508633Z","iopub.status.idle":"2021-12-03T18:42:07.941000Z","shell.execute_reply.started":"2021-12-03T18:40:40.508591Z","shell.execute_reply":"2021-12-03T18:42:07.940226Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"titlos_mark2 = 'The accuracies for the classifiers with default parameters and different metrics' \nepikefalides_mark2 = ['Classifiers', 'Dummy', 'MLP', 'SVC']\ndedomena_mark2 = [('Accuracy Score', str(clfs3_10F_accur_scores[0]),str(clfs3_10F_accur_scores[1]),str(clfs3_10F_accur_scores[2])),\n                  ('Accuracy times', str(clfs3_10F_accur_times[0]),str(clfs3_10F_accur_times[1]),str(clfs3_10F_accur_times[2])),\n                  ('f1 macro', str(clfs3_10F_f1_scores[0]), str(clfs3_10F_f1_scores[1]), str(clfs3_10F_f1_scores[2])),\n                  ('f1 macro times', str(clfs3_10F_f1_times[0]), str(clfs3_10F_f1_times[1]), str(clfs3_10F_f1_times[2])),\n                  ('Recall', str(clfs3_10F_recall_scores[0]), str(clfs3_10F_recall_scores[1]), str(clfs3_10F_recall_scores[2])),\n                  ('Recall times', str(clfs3_10F_recall_times[0]), str(clfs3_10F_recall_times[1]), str(clfs3_10F_recall_times[2])),\n                  ('Precision', str(clfs3_10F_precision_scores[0]), str(clfs3_10F_precision_scores[1]), str(clfs3_10F_precision_scores[2])),\n                  ('Precision times', str(clfs3_10F_precision_times[0]), str(clfs3_10F_precision_times[1]), str(clfs3_10F_precision_times[2]))]\n\nmarkdownCreator(titlos_mark2, epikefalides_mark2, dedomena_mark2)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T18:42:58.827494Z","iopub.execute_input":"2021-12-03T18:42:58.828118Z","iopub.status.idle":"2021-12-03T18:42:58.839205Z","shell.execute_reply.started":"2021-12-03T18:42:58.828072Z","shell.execute_reply":"2021-12-03T18:42:58.838450Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"clfs3_names = [\"Dummy\",\"MLP\",\"SVC\"]\nplot_AccurANDf1(clfs3_10F_accur_scores, clfs3_10F_f1_scores, clfs3_names, ['accuracy','f1_macro'], \"Accuracy per Classifier with 10 fold cross validation\")\nplot_AccurANDf1(clfs3_10F_recall_scores, clfs3_10F_precision_scores, clfs3_names, ['Recall','Precision'], \"Recall-Precision per Classifier with 10 fold cross validation\")\n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T18:51:14.365211Z","iopub.execute_input":"2021-12-03T18:51:14.365483Z","iopub.status.idle":"2021-12-03T18:51:14.777122Z","shell.execute_reply.started":"2021-12-03T18:51:14.365444Z","shell.execute_reply":"2021-12-03T18:51:14.776367Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nimport optuna\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\ndef objective(trial):\n\n    # split data\n    x_balanced=X_down\n    cdf= pd.DataFrame(y_down)\n    class_mapping = {label:idx for idx,label in enumerate(np.unique(cdf[0]))}\n    # και κάνουμε την μετατροπή\n    cdf[0] = cdf[0].map(class_mapping)  \n    y_new=cdf[0].values\n\n    y_balanced=y_new\n    x_train,x_test,y_train,y_test = train_test_split(x_balanced,y_balanced,test_size=0.3,shuffle=True)\n    print(np.var(x_train,axis=0))\n    # Sample hyper parameters\n    classifier_name = trial.suggest_categorical(\"classifier\", [\"MLP\",\n                                                               \"SVC\"])\n    if classifier_name==\"MLP\":\n\n        # Sample hyper parameters\n        # Construct the model\n        threshold= trial.suggest_int('threshold', 0,6e+03,step=100)\n        n_components=trial.suggest_int('n_componenets', 2, 5,step=1)\n        activation=trial.suggest_categorical('activation',['tanh','relu'])\n        solver=trial.suggest_categorical('solver',['sgd','adam'])\n        alpha=trial.suggest_discrete_uniform('alpha' ,0.0001, 0.005,0.001)\n        learning_rate=trial.suggest_categorical('learning_rate',['constant','adaptive'])\n        clf=MLPClassifier(hidden_layer_sizes= (50,100,50),activation=activation,solver=solver,alpha=alpha,\n                          learning_rate=learning_rate)\n        pipe= Pipeline([('selector',VarianceThreshold(threshold=threshold )),('scaler',StandardScaler()),\n                             ('pca',PCA(n_components=n_components)),\n                             ('clf',clf)],memory='tmp')\n                           \n    elif classifier_name==\"SVC\":\n        \n\n        # Sample hyper parameters\n        C = trial.suggest_loguniform('C', 1e-10, 1)\n        kernel = trial.suggest_categorical('kernel',['poly','rbf','sigmoid'])\n        degree = trial.suggest_int('degree',1, 50)\n        gamma = trial.suggest_loguniform('gamma',0.001,10000)\n        threshold= trial.suggest_int('threshold', 0 ,6e+03,step=100)\n        n_components=trial.suggest_int('n_components', 2, 5,step=1)\n        # Construct the model\n        clf = SVC(C=C, kernel=kernel, degree=degree,gamma=gamma)\n        pipe= Pipeline([('selector',VarianceThreshold(threshold=threshold )),('scaler',StandardScaler()),\n                             ('pca',PCA(n_components=n_components)),\n                             ('clf',clf)],memory='tmp')\n    \n    # Train the model\n    pipe.fit(x_train,y_train)\n\n    # Evaluate the model\n    y_pred_test = pipe.predict(x_test)\n    loss = mean_squared_error(y_test,y_pred_test)\n    print(\"Test Score:\",pipe.score(x_test,y_test))\n    print(\"Train Score:\",pipe.score(x_train,y_train))\n    print(classification_report(y_test,y_pred_test))\n    print(\"\\n=================\")\n    return loss","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='minimize')\n\n# start tuning for the hyper-parameters\nstudy.optimize(objective, n_trials=50)","metadata":{},"execution_count":null,"outputs":[]}]}
